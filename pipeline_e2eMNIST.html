<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="css/style.css" rel="stylesheet" type="text/css">
    <title>Learning Studio Manual</title>
</head>
<body>

    <div class="two">
        <h1>러닝스튜디오 기능별 가이드
          <span>Learning studio Manual</span>
        </h1>
    </div>

    <div class="button-container">
        <button class="custom-btn btn-3" onclick="window.location.href='notebook.html'"><span>노트북</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='tensorboard.html'"><span>텐서보드</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='katib.html'"><span>AutoML</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href=''"><span style="font-size: xx-small;">하이퍼파라미터튜닝 예제</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='serving.html'"><span>서빙</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='pipeline.html'"><span>파이프라인</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='pipeline-experiments.html'"><span>파이프라인 실험</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='pipeline-recurringruns.html'"><span>파이프라인 스케줄링</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='pipeline_SDK.html'"><span>파이프라인 SDK 안내</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='pipeline_e2eMNIST.html'"><span style="font-size: xx-small;">파이프라인_학습부터서빙</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href=''"><span style="font-size: xx-small;">파이프라인예제 코드모음</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='volume.html'"><span>볼륨</span></button>
        <button class="custom-btn btn-3" onclick="window.location.href='manage-users.html'"><span>리소스 공유 관리</span></button>
    </div>

    <section>
        <h2>End to End 파이프라인 생성하기 (MNIST 모델 활용)</h2>
        <p class="board">학습, 하이퍼파라미터튜닝, 모델 서빙까지 하나의 파이프라인으로 생성하는 예제입니다.</p>
        <p>이 예제는 하이퍼 파라미터 튜닝부터 모델 자동 서빙까지 진행되는 파이프라인을 제공하는 예제로,
            노트북에서 진행되는 것을 전제 조건으로 하고 있습니다.</p>
            <p>이 예제는 이미지 분류 모델인 MNSIT 모델을 기반으로 테스트 되었으며,
            4가지를 중점으로 설명하고 있습니다.</p>
            <ul>
            <li>Katib을 이용한 하이퍼 파라미터 튜닝 코드 작성 예제</li>
            <li>TFJob을 이용한 분산교육 파드 생성 코드</li>
            <li>Kserve를 이용한 모델 배포 및 서빙</li>
            <li>API 서비스를 이용하여 모델에게 추론 요청하기</li>
            </ul>
            <h2 id="step1-sdk-import">Step1. 파이프라인 및 관련 SDK  설치 및 패키지 Import</h2>
            <ul>
            <li>SDK설치</li>
            </ul>
            <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
            <pre><code class="lang-python">!pip install kfp==1.8.4
!pip install kubeflow-katib==0.12.0
!pip install urllib3==1.26.15</code></pre>
            <ul>
            <li>패키지 Import</li>
            </ul>
            <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
            <pre><code class="lang-python">import kfp
import kfp.dsl as dsl
from kfp import components

from kubeflow.katib import ApiClient
from kubeflow.katib import V1beta1ExperimentSpec
from kubeflow.katib import V1beta1AlgorithmSpec
from kubeflow.katib import V1beta1ObjectiveSpec
from kubeflow.katib import V1beta1ParameterSpec
from kubeflow.katib import V1beta1FeasibleSpace
from kubeflow.katib import V1beta1TrialTemplate
from kubeflow.katib import V1beta1TrialParameterSpec
            </code></pre>
            <h2 id="step2-">Step2. 파라미터 튜닝을 위한 매개변수 정의 및 파이프라인 컴포넌트화</h2>
            <ul>
            <li>검색 알고리즘 , 매개변수 및 워커 노드 수 정의,  MNIST용 평가판 템플릿 정의 등 katib SDK 활용 후 파이프라인 컴포넌트 화</li>
            </ul>
            <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
<pre><code><span class="hljs-comment"># 인수에서 실험 이름, 네임스페이스 및 교육 단계 수를 정의해야 합니다.</span>

def create_katib_experiment_task(experiment_name, experiment_namespace, training_steps):
    <span class="hljs-comment"># 시행될 회수 지정</span>
    <span class="hljs-attr">max_trial_count</span> = <span class="hljs-number">20</span>  <span class="hljs-comment">##최대 시도</span>
    <span class="hljs-attr">max_failed_trial_count</span> = <span class="hljs-number">3</span> <span class="hljs-comment">##최대 실패 </span>
    <span class="hljs-attr">parallel_trial_count</span> = <span class="hljs-number">4</span>  <span class="hljs-comment">##병렬 개수</span>

    <span class="hljs-comment"># 오브젝트 정의</span>
    <span class="hljs-attr">objective</span> = V1beta1ObjectiveSpec(
        <span class="hljs-attr">type="minimize",</span>
        <span class="hljs-attr">goal=0.001,</span>
        <span class="hljs-attr">objective_metric_name="loss"</span>
    )

    <span class="hljs-comment"># 검색 알고리즘 정의 : 예제에서는 'random' 사용(Grid search, Bayesian optimization, HYPERBAND 등)</span>
    <span class="hljs-attr">algorithm</span> = V1beta1AlgorithmSpec(
        <span class="hljs-attr">algorithm_name="random",</span>
    )

    <span class="hljs-comment"># learning rate, 배치 사이즈 등 매개변수 초기화</span>
    <span class="hljs-attr">parameters</span> = [
        V1beta1ParameterSpec(
            <span class="hljs-attr">name="learning_rate",</span>
            <span class="hljs-attr">parameter_type="double",</span>
            <span class="hljs-attr">feasible_space=V1beta1FeasibleSpace(</span>
                <span class="hljs-attr">min="0.01",</span>
                <span class="hljs-attr">max="0.05"</span>
            ),
        ),
        V1beta1ParameterSpec(
            <span class="hljs-attr">name="batch_size",</span>
            <span class="hljs-attr">parameter_type="int",</span>
            <span class="hljs-attr">feasible_space=V1beta1FeasibleSpace(</span>
                <span class="hljs-attr">min="80",</span>
                <span class="hljs-attr">max="100"</span>
            ),
        )
    ]

    <span class="hljs-comment">## 실험 평가판 템플릿은 MNIST 예제임로 ""docker.io/liuhougangxa/tf-estimator-mnist"를 이용하는 것으로 yaml 정의</span>
    <span class="hljs-attr">trial_spec</span> = {
        <span class="hljs-string">"apiVersion"</span>: <span class="hljs-string">"kubeflow.org/v1"</span>,
        <span class="hljs-string">"kind"</span>: <span class="hljs-string">"TFJob"</span>,
        <span class="hljs-string">"spec"</span>: {
            <span class="hljs-string">"tfReplicaSpecs"</span>: {
                <span class="hljs-string">"Chief"</span>: {
                    <span class="hljs-string">"replicas"</span>: <span class="hljs-number">1</span>,
                    <span class="hljs-string">"restartPolicy"</span>: <span class="hljs-string">"OnFailure"</span>,
                    <span class="hljs-string">"template"</span>: {
                        <span class="hljs-string">"metadata"</span>: {
                            <span class="hljs-string">"annotations"</span>: {
                                <span class="hljs-string">"sidecar.istio.io/inject"</span>: <span class="hljs-string">"false"</span>
                            }
                        },
                        <span class="hljs-string">"spec"</span>: {
                            <span class="hljs-string">"containers"</span>: [
                                {
                                    <span class="hljs-string">"name"</span>: <span class="hljs-string">"tensorflow"</span>,
                                    <span class="hljs-string">"image"</span>: <span class="hljs-string">"docker.io/liuhougangxa/tf-estimator-mnist"</span>,
                                    <span class="hljs-string">"command"</span>: [
                                        <span class="hljs-string">"python"</span>,
                                        <span class="hljs-string">"/opt/model.py"</span>,
                                        <span class="hljs-string">"--tf-train-steps="</span> + str(training_steps),
                                        <span class="hljs-string">"--tf-learning-rate=<span class="hljs-subst">${trialParameters.learningRate}</span>"</span>,
                                        <span class="hljs-string">"--tf-batch-size=<span class="hljs-subst">${trialParameters.batchSize}</span>"</span>
                                    ]
                                }
                            ]
                        }
                    }
                },
                <span class="hljs-string">"Worker"</span>: {
                    <span class="hljs-string">"replicas"</span>: <span class="hljs-number">1</span>,
                    <span class="hljs-string">"restartPolicy"</span>: <span class="hljs-string">"OnFailure"</span>,
                    <span class="hljs-string">"template"</span>: {
                        <span class="hljs-string">"metadata"</span>: {
                            <span class="hljs-string">"annotations"</span>: {
                                <span class="hljs-string">"sidecar.istio.io/inject"</span>: <span class="hljs-string">"false"</span>
                            }
                        },
                        <span class="hljs-string">"spec"</span>: {
                            <span class="hljs-string">"containers"</span>: [
                                {
                                    <span class="hljs-string">"name"</span>: <span class="hljs-string">"tensorflow"</span>,
                                    <span class="hljs-string">"image"</span>: <span class="hljs-string">"docker.io/liuhougangxa/tf-estimator-mnist"</span>,
                                    <span class="hljs-string">"command"</span>: [
                                        <span class="hljs-string">"python"</span>,
                                        <span class="hljs-string">"/opt/model.py"</span>,
                                        <span class="hljs-string">"--tf-train-steps="</span> + str(training_steps),
                                        <span class="hljs-string">"--tf-learning-rate=<span class="hljs-subst">${trialParameters.learningRate}</span>"</span>,
                                        <span class="hljs-string">"--tf-batch-size=<span class="hljs-subst">${trialParameters.batchSize}</span>"</span>
                                    ]
                                }
                            ]
                        }
                    }
                }
            }
        }
    }

    <span class="hljs-comment">#  Trial template에 사용할 V1beta1TrialTemplate() 기반으로  매개변수 선언</span>
    <span class="hljs-attr">trial_template</span> = V1beta1TrialTemplate(
        <span class="hljs-attr">primary_container_name="tensorflow",</span>
        <span class="hljs-attr">trial_parameters=[</span>
            V1beta1TrialParameterSpec(
                <span class="hljs-attr">name="learningRate",</span>
                <span class="hljs-attr">description="Learning</span> rate for the training model<span class="hljs-string">",
                reference="</span>learning_rate<span class="hljs-string">"
            ),
            V1beta1TrialParameterSpec(
                name="</span>batchSize<span class="hljs-string">",
                description="</span>Batch size for the model<span class="hljs-string">",
                reference="</span>batch_size<span class="hljs-string">"
            ),
        ],
        trial_spec=trial_spec
    )

    # 위에서 정의한 변수 값으로 실험(Experiment) 생성하기.
    experiment_spec = V1beta1ExperimentSpec(
        max_trial_count=max_trial_count,
        max_failed_trial_count=max_failed_trial_count,
        parallel_trial_count=parallel_trial_count,
        objective=objective,
        algorithm=algorithm,
        parameters=parameters,
        trial_template=trial_template
    )

    # 하이퍼 파마리터 튜닝을 위한 파이프라인 컴포넌트 생성
    katib_experiment_launcher_op = components.load_component_from_url(
        "</span>https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/katib-launcher/component.yaml<span class="hljs-string">")
    op = katib_experiment_launcher_op(
        experiment_name=experiment_name,
        experiment_namespace=experiment_namespace,
        experiment_spec=ApiClient().sanitize_for_serialization(experiment_spec),
        experiment_timeout_minutes=60,
        delete_finished_experiment=False)

    return op</span>
</code></pre>   
    </section>
    <section>
        <h2 id="step2-tfjob-">Step3. 분산 학습을 위한 TFJob 생성 및 파이프라인 컴포넌트화</h2>
        <p>TFJob이란 <strong> 쿠베네티스에서 텐서플로우 분산 job을 실행할 수 있는 쿠버네티스 커스텀 리소스(CRD) </strong>입니다.
        그 외 Job : PyTorchJob, MXJob, MPIJob 등이 있습니다.</p>
        <p>잡은 다음의 프로세스를 수행할 수 있습니다.</p>
        <ul>
        <li>Cheif : 트레이닝의 조율/분배와 모델 체크포인트 생성같은 일들을 담당</li>
        <li>Ps : 파라미터 서버로 모델의 파라미터를 위해 분상된 데이터 스토어를 제공</li>
        <li>Worker : 모델을 실제로 트레이닝하는 역할</li>
        <li>Evaluator : 모델이 트레이닝중일때 평가지표를 산출하는 일</li>
        </ul>
        <p>참고로 worker 역할을 하는 job에게 GPU를 개수를 정의할 수 있습니다.</p>
        <pre><code>(중략)
resource<span class="hljs-variable">s:</span>
    limit<span class="hljs-variable">s:</span>
        nvidia.<span class="hljs-keyword">com</span>/gpu: <span class="hljs-number">1</span>
(생략)</code></pre>
    <h3 id="-">베스트 결과값 리턴 함수 코드</h3>
    <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">convert_katib_results</span><span class="hljs-params">(katib_results)</span> -&gt; str:</span>
    <span class="hljs-keyword">import</span> json
    <span class="hljs-keyword">import</span> pprint
    katib_results_json = json.loads(katib_results)
    print(<span class="hljs-string">"Katib results:"</span>)
    pprint.pprint(katib_results_json)
    best_hps = []
    <span class="hljs-keyword">for</span> pa <span class="hljs-keyword">in</span> katib_results_json[<span class="hljs-string">"currentOptimalTrial"</span>][<span class="hljs-string">"parameterAssignments"</span>]:
        <span class="hljs-keyword">if</span> pa[<span class="hljs-string">"name"</span>] == <span class="hljs-string">"learning_rate"</span>:
            best_hps.append(<span class="hljs-string">"--tf-learning-rate="</span> + pa[<span class="hljs-string">"value"</span>])
        <span class="hljs-keyword">elif</span> pa[<span class="hljs-string">"name"</span>] == <span class="hljs-string">"batch_size"</span>:
            best_hps.append(<span class="hljs-string">"--tf-batch-size="</span> + pa[<span class="hljs-string">"value"</span>])
    print(<span class="hljs-string">"Best Hyperparameters: {}"</span>.format(best_hps))
    <span class="hljs-keyword">return</span> <span class="hljs-string">" "</span>.join(best_hps)</code></pre>
        
            <h3 id="tfjob-">TFJob 생성 및 파이프라인 컴포넌트화</h3>
            <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
        <pre><code>def create_tfjob_task(tfjob_name, tfjob_namespace, training_steps, katib_op, model_volume_op):
    <span class="hljs-built_in">import</span> json

    <span class="hljs-comment"># katib 실험에서 파라미터를 가져옵니다.</span>
    <span class="hljs-comment"># 매개 변수 : "--tf-learning-rate=0.01  , --tf- batch-size=100" 형식입니다</span>
    <span class="hljs-attr">convert_katib_results_op</span> = components.func_to_container_op(convert_katib_results)
    <span class="hljs-attr">best_hp_op</span> = convert_katib_results_op(katib_op.output)
    <span class="hljs-attr">best_hps</span> = str(best_hp_op.output)

    <span class="hljs-comment"># 최상의 하이퍼 파라미터로 TFJob Chief 및 Worker 사양을 작성합니다.</span>
    <span class="hljs-comment">## Chief : model orchestrating 역할을 하는 스펙 리소스</span>
    <span class="hljs-attr">tfjob_chief_spec</span> = {
        <span class="hljs-string">"replicas"</span>: <span class="hljs-number">1</span>,
        <span class="hljs-string">"restartPolicy"</span>: <span class="hljs-string">"OnFailure"</span>,
        <span class="hljs-string">"template"</span>: {
            <span class="hljs-string">"metadata"</span>: {
                <span class="hljs-string">"annotations"</span>: {
                    <span class="hljs-string">"sidecar.istio.io/inject"</span>: <span class="hljs-string">"false"</span>
                }
            },
            <span class="hljs-string">"spec"</span>: {
                <span class="hljs-string">"containers"</span>: [
                    {
                        <span class="hljs-string">"name"</span>: <span class="hljs-string">"tensorflow"</span>,
                        <span class="hljs-string">"image"</span>: <span class="hljs-string">"docker.io/liuhougangxa/tf-estimator-mnist"</span>,
                        <span class="hljs-string">"command"</span>: [
                            <span class="hljs-string">"sh"</span>,
                            <span class="hljs-string">"-c"</span>
                        ],
                        <span class="hljs-string">"args"</span>: [
                            <span class="hljs-string">"python /opt/model.py --tf-export-dir=/mnt/export --tf-train-steps={} {}"</span>.format(training_steps, best_hps)
                        ],
                        <span class="hljs-string">"volumeMounts"</span>: [
                            {
                                <span class="hljs-string">"mountPath"</span>: <span class="hljs-string">"/mnt/export"</span>,
                                <span class="hljs-string">"name"</span>: <span class="hljs-string">"model-volume"</span>
                            }
                        ]
                    }
                ],
                <span class="hljs-string">"volumes"</span>: [
                    {
                        <span class="hljs-string">"name"</span>: <span class="hljs-string">"model-volume"</span>,
                        <span class="hljs-string">"persistentVolumeClaim"</span>: {
                            <span class="hljs-string">"claimName"</span>: str(model_volume_op.outputs[<span class="hljs-string">"name"</span>])
                        }
                    }
                ]
            }
        }
    }

    <span class="hljs-comment">#분산 학습을 하는 worker spec 리소스 정의</span>
    <span class="hljs-attr">tfjob_worker_spec</span> = {
        <span class="hljs-string">"replicas"</span>: <span class="hljs-number">1</span>,
        <span class="hljs-string">"restartPolicy"</span>: <span class="hljs-string">"OnFailure"</span>,
        <span class="hljs-string">"template"</span>: {
            <span class="hljs-string">"metadata"</span>: {
                <span class="hljs-string">"annotations"</span>: {
                    <span class="hljs-string">"sidecar.istio.io/inject"</span>: <span class="hljs-string">"false"</span>
                }
            },
            <span class="hljs-string">"spec"</span>: {
                <span class="hljs-string">"containers"</span>: [
                    {
                        <span class="hljs-string">"name"</span>: <span class="hljs-string">"tensorflow"</span>,
                        <span class="hljs-string">"image"</span>: <span class="hljs-string">"docker.io/liuhougangxa/tf-estimator-mnist"</span>,
                        <span class="hljs-string">"command"</span>: [
                            <span class="hljs-string">"sh"</span>,
                            <span class="hljs-string">"-c"</span>,
                        ],
                        <span class="hljs-string">"args"</span>: [
                            <span class="hljs-string">"python /opt/model.py --tf-export-dir=/mnt/export --tf-train-steps={} {}"</span>.format(training_steps, best_hps) 
                        ],
                    }
                ],
            }
        }
    }

    <span class="hljs-comment"># 외부에서 제공하는 컴포넌트 리소스를 활용하여 TFJob에 대한 pipeline 태스크 생성</span>
    <span class="hljs-attr">tfjob_launcher_op</span> = components.load_component_from_url(
        <span class="hljs-string">"https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kubeflow/launcher/component.yaml"</span>)
    <span class="hljs-attr">op</span> = tfjob_launcher_op(
        <span class="hljs-attr">name=tfjob_name,</span>
        <span class="hljs-attr">namespace=tfjob_namespace,</span>
        <span class="hljs-attr">chief_spec=json.dumps(tfjob_chief_spec),</span>
        <span class="hljs-attr">worker_spec=json.dumps(tfjob_worker_spec),</span>
        <span class="hljs-attr">tfjob_timeout_minutes=60,</span>
        <span class="hljs-attr">delete_finished_tfjob=False)</span>
    return op</code></pre>       
    </section>
    <section>
        <h2 id="step3-">Step4. 모델 배포/서빙하는 파이프라인 컴포넌트화</h2>
        <p>katib를 통한 하이퍼 파라미터 튜닝과 TFjob를 이용한 분산학습 결과로 생성된 모델 파일을 서빙하는 파이프라인 작성</p>
        <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
        <pre><code><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_serving_task</span><span class="hljs-params">(model_name, model_namespace, tfjob_op, model_volume_op)</span>:</span>
    <span class="hljs-comment"># API 버전 정보 정의 및 컴포넌트(kserving 컴포넌트)를 외부에서 참조할 수 있도록 정의</span>
    api_version = <span class="hljs-string">'serving.kserve.io/v1beta1'</span>
    serving_component_url = <span class="hljs-string">'https://raw.githubusercontent.com/kubeflow/pipelines/master/components/kserve/component.yaml'</span>

    inference_service = <span class="hljs-string">'''
apiVersion: "{}"
kind: "InferenceService"
metadata:
  name: {}
  namespace: {}
  annotations:
    "sidecar.istio.io/inject": "false"
spec:
  predictor:
    tensorflow:
      storageUri: "pvc://{}/"
'''</span>.format(api_version, model_name, model_namespace, str(model_volume_op.outputs[<span class="hljs-string">"name"</span>]))

    serving_launcher_op = components.load_component_from_url(serving_component_url)
    <span class="hljs-comment">#.after()로 tfjob오퍼레이터가 종료된 후에 실행하도록 설정</span>
    serving_launcher_op(action=<span class="hljs-string">"apply"</span>, inferenceservice_yaml=inference_service).after(tfjob_op)
</code></pre>
    </section>
    <section>
        <h2 id="step5-">Step5. 파이프라인 생성 및 컴파일</h2>
        <p>이제 위에서 생성한 각 스텝별 파이프라인 컴포넌트를 실행하는 파이프라인을 작성하고 컴파일을 통해 파이프라인 파일을 생성한다.</p>
        <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
<pre><code><span class="hljs-built_in">name</span>=<span class="hljs-string">"mnist-e2e-30"</span>  <span class="hljs-comment">##서빙 모델 이름</span>
namespace=<span class="hljs-string">"kubeflow-user-example-com"</span> <span class="hljs-comment">##서빙 네임스페이스</span>
training_steps=<span class="hljs-string">"2"</span>  <span class="hljs-comment">## 학습 횟수 정의</span>


@dsl.pipeline(
    <span class="hljs-built_in">name</span>=<span class="hljs-string">"End to End Pipeline"</span>,
    description=<span class="hljs-string">"An end to end mnist example including hyperparameter tuning, train and inference"</span>
)
def mnist_pipeline(<span class="hljs-built_in">name</span>=<span class="hljs-built_in">name</span>, namespace=namespace, training_steps=training_steps):
    <span class="hljs-comment">#  하이퍼 파라미터 튜닝 파이프라인 컴포넌트</span>
    katib_op = create_katib_experiment_task(<span class="hljs-built_in">name</span>, namespace, training_steps)

    <span class="hljs-comment">#모델을 훈련하고 제공할 볼륨을 생성 컴포넌트</span>
    model_volume_op = dsl.VolumeOp(
        <span class="hljs-built_in">name</span>=<span class="hljs-string">"model-volume"</span>,
        resource_name=<span class="hljs-string">"model-volume"</span>,
        size=<span class="hljs-string">"1Gi"</span>,
        modes=dsl.VOLUME_MODE_RWO
    )

    <span class="hljs-comment"># TFJob과 함께 분산 교육 파이프라인 컴포넌트</span>
    <span class="hljs-comment"># 객체명은 서빙 컴포넌트 코드의 .after(tfjob_op) 과 같음.</span>
    tfjob_op = create_tfjob_task(<span class="hljs-built_in">name</span>, namespace, training_steps, katib_op, model_volume_op)

    <span class="hljs-comment"># 모델 서빙 생성 컴포넌트</span>
    create_serving_task(<span class="hljs-built_in">name</span>, namespace, tfjob_op, model_volume_op)

<span class="hljs-comment">##파이프라인 이름 정의 </span>
pipeline_filename = mnist_pipeline.__name__ + '.pipeline.zip'

<span class="hljs-comment">##파이프라인 컴파일</span>
kfp.compiler.Compiler().compile(mnist_pipeline, pipeline_filename)</code></pre>
<ul>
    <li>(옵션)노트북 위에서 직접 실험 진행 테스트 진행 </li>
    </ul>
    <pre><code><span class="hljs-comment"># 파이프라인 클라이언트 객체 선언</span>
<span class="hljs-attr">kfp_client=kfp.Client()</span>
<span class="hljs-attr">run_id</span> = kfp_client.create_run_from_pipeline_func(mnist_pipeline, <span class="hljs-attr">namespace=namespace,</span> <span class="hljs-attr">arguments={}).run_id</span>

<span class="hljs-comment"># 클라이언트 실행 값을 이용하여 노트 위에서 파이프라인 직접 실행</span>
print(<span class="hljs-string">"Run ID: "</span>, run_id)</code></pre>     
    </section>
    <section>
        <h2 id="step6-">Step6. 서빙 모델에게 추론 테스트하기</h2>
        <p>Mnist 손글씨 분류 모델에 직접 이미지 데이터를 질문셋으로 입력하여 정답을 맞추는지 테스트
        예제 이미지 : 손글씨 9</p>
        <p>러닝 스튜디오는 <strong> 서빙추론 API 명세서 </strong>를 제공하고 있으므로, <strong> 모델 서빙이 완성되면 REST API를 통한 모델 추론 또한 가능 </strong>.</p>
        <span style="font-size: 10px; padding-left: 20px; font-weight:bold">(코드복사)</span>
<pre><code><span class="hljs-keyword">import</span> numpy as np
from PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> requests

name=<span class="hljs-string">"mnist-e2e-10"</span>  ##서빙 이름
<span class="hljs-keyword">namespace</span>=<span class="hljs-string">"kubeflow-user-example-com"</span> ##서빙 네임스페이스


# Specify the <span class="hljs-built_in">image</span> URL here. 숫자 이미지
image_url = <span class="hljs-string">"https://raw.githubusercontent.com/kubeflow/katib/master/examples/v1beta1/kubeflow-pipelines/images/9.bmp"</span>
<span class="hljs-built_in">image</span> = Image.<span class="hljs-built_in">open</span>(requests.<span class="hljs-built_in">get</span>(image_url, stream=True).raw)
data = np.<span class="hljs-keyword">array</span>(<span class="hljs-built_in">image</span>.convert(<span class="hljs-string">'L'</span>).resize((<span class="hljs-number">28</span>, <span class="hljs-number">28</span>))).astype(np.<span class="hljs-keyword">float</span>).reshape(<span class="hljs-number">-1</span>, <span class="hljs-number">28</span>, <span class="hljs-number">28</span>, <span class="hljs-number">1</span>)
data_formatted = np.array2string(data, separator=<span class="hljs-string">","</span>, formatter={<span class="hljs-string">"float"</span>: lambda x: <span class="hljs-string">"%.1f"</span> % x})

json_request = <span class="hljs-string">'{{ "instances" : {} }}'</span>.format(data_formatted)

# 모델의 엔드포인트  URL은 상단에서 정의한 모델의 name과 사용자의 <span class="hljs-keyword">namespace</span> 정보를 조합하여 생성 됨.
url = <span class="hljs-string">"http://{}-predictor-default.{}.svc.cluster.local/v1/models/{}:predict"</span>.format(name, <span class="hljs-keyword">namespace</span>, name)
response = requests.post(url, data=json_request)

<span class="hljs-built_in">print</span>(<span class="hljs-string">"질문한 이미지 정보"</span>)
<span class="hljs-built_in">display</span>(<span class="hljs-built_in">image</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">""</span>)
<span class="hljs-built_in">print</span>(<span class="hljs-string">"예측 답변"</span>)
<span class="hljs-built_in">print</span>(response.json())</code></pre>        
    </section>
    <section>
        <h2 id="-token-error-">기타(옵션). Token Error 가 나타날 경우</h2>
        <p>&#39;Mnist e2e&#39; 예제는 멀티유저모드로 실행됩니다. &#39;ERROR:root:Failed to read a token from file &#39;/var/run/secrets/kubeflow/pipelines/token&#39;&#39;가 <strong> 발생해도 예제를 실습하는데는 문제가 없으나 </strong>, 에러 없이 실행하고 싶을 경우 secret 관련한 CRD를 네임스페이스를 지정하여 실행해주면 에러가 사라집니다.</p>
        <h5 id="-intention-">주의 : intention(들여쓰기)를 조심해 주세요.</h5>
        <ul>
        <li>터미널을 실행해서 진행해 주세요 ( &#39;file &gt; new &gt; terminal &#39; 선택)<pre><code class="lang-sh"><span class="hljs-variable">$ </span>vi podDedaults.yaml
        </code></pre>
        </li>
        <li>아래 코드를 복사/붙혀넣기 해주시고 저장해주세요.</li>
        </ul>
        <pre><code class="lang-yaml"><span class="hljs-attr">apiVersion:</span> kubeflow.org/v1alpha1
<span class="hljs-attr">kind:</span> PodDefault
<span class="hljs-attr">metadata:</span>
<span class="hljs-attr">  name:</span> access-ml-pipeline
<span class="hljs-attr">  namespace:</span> <span class="hljs-string">"kubeflow-user-example-com"</span> <span class="hljs-comment"># 이 부분 변경 : 네임스페이스 정보</span>
<span class="hljs-attr">spec:</span>
<span class="hljs-attr">  desc:</span> Allow access to Kubeflow Pipelines
<span class="hljs-attr">  selector:</span>
<span class="hljs-attr">    matchLabels:</span>
<span class="hljs-attr">      access-ml-pipeline:</span> <span class="hljs-string">"true"</span>
<span class="hljs-attr">  env:</span>
<span class="hljs-bullet">    -</span> <span class="hljs-comment">## this environment variable is automatically read by `kfp.Client()`</span>
        <span class="hljs-comment">## this is the default value, but we show it here for clarity</span>
<span class="hljs-attr">      name:</span> KF_PIPELINES_SA_TOKEN_PATH
<span class="hljs-attr">      value:</span> /var/run/secrets/kubeflow/pipelines/token
<span class="hljs-attr">  volumes:</span>
<span class="hljs-attr">    - name:</span> volume-kf-pipeline-token
<span class="hljs-attr">      projected:</span>
<span class="hljs-attr">        sources:</span>
<span class="hljs-attr">          - serviceAccountToken:</span>
<span class="hljs-attr">              path:</span> token
<span class="hljs-attr">              expirationSeconds:</span> <span class="hljs-number">7200</span>
                <span class="hljs-comment">## defined by the `TOKEN_REVIEW_AUDIENCE` environment variable on the `ml-pipeline` deployment</span>
<span class="hljs-attr">              audience:</span> pipelines.kubeflow.org
<span class="hljs-attr">  volumeMounts:</span>
<span class="hljs-attr">    - mountPath:</span> /var/run/secrets/kubeflow/pipelines
<span class="hljs-attr">      name:</span> volume-kf-pipeline-token
<span class="hljs-attr">      readOnly:</span> <span class="hljs-literal">true</span></code></pre>
<ul>
<li>생성한 podDedaults.yaml 파일을 터미널(위치</li>
</ul>
<pre><code class="lang-sh">$ kubectl apply <span class="hljs-_">-f</span> podDedaults.yaml
</code></pre>
<p>이제 token 관련 에러 없이 예제를 테스트할 수 있습니다.</p>
        
    </section>
    <footer>
        <p>&copy; 2024 솔트룩스 러닝 스튜디오</p>
    </footer>

</body>
</html>
